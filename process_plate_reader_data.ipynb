{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "import openpyxl\n",
    "import re\n",
    "import argparse, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/codymartin/Documents/CPT/N4/plate_reader'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/codymartin/Documents/CPT/N4/plate_reader/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WellPlate:\n",
    "    def __init__(self, data, setup, active_sheet=0, outdir=\"output\"):\n",
    "        self.file = data\n",
    "        self.outdir = outdir\n",
    "        '''\n",
    "        Read in excel workbook witn openpyxl\n",
    "        '''\n",
    "        self.workbook = openpyxl.load_workbook(self.file, read_only=True)\n",
    "        \n",
    "        '''\n",
    "        Extract information from the plate setup file\n",
    "        '''\n",
    "        self.plate_setup = pd.read_csv(setup, dtype={i+1 : str for i in range(12)}).set_index(\"row\")\n",
    "        \n",
    "        '''\n",
    "        Excel worksheets can have different sheets. Here we need to set the active\n",
    "        sheet to the sheet with the raw data.\n",
    "        '''\n",
    "        self.workbook.active = active_sheet\n",
    "        self.sheet = self.workbook.active # nicer name to use later\n",
    "        \n",
    "        '''\n",
    "        Make a list of all cell values grouped into tuples per row. \n",
    "        '''\n",
    "        self.data = list(self.sheet.values)\n",
    "        \n",
    "        '''\n",
    "        Keep track of metadata, which is approximately, the first 59 lines or so.\n",
    "        '''\n",
    "        self.metadata = self.data[0:58]\n",
    "        \n",
    "        '''\n",
    "        Keep track of points per well, or measurements taken per well. This is\n",
    "        stored in the metadata, so it can be calculated.\n",
    "        '''\n",
    "        self.ppw_row = ()\n",
    "        for row in self.metadata:\n",
    "            for cell in row:\n",
    "                if isinstance(cell, str): # Data types include str, None, and time, only want strings\n",
    "                    if \"Multiple Reads per Well\" in cell:\n",
    "                        self.ppw_row = row\n",
    "            if self.ppw_row: # only true if self.ppw_row is assigned in line above \n",
    "                break\n",
    "                # end search since usually there is a second row with the same\n",
    "                # \"Multiple Reads per Well\" afterward that gives the area of the\n",
    "                # measurements\n",
    "\n",
    "        for cell in self.ppw_row:\n",
    "            if cell == None: # Skip empty cells\n",
    "                continue\n",
    "            # The measurements per well will be in this pattern: # x #\n",
    "            # We can grab the cell that has that pattern with this simple\n",
    "            # regular expression. This command will return None for no\n",
    "            # matches. Otherwise, it will return the matching string itself.\n",
    "            elif re.search(\"\\d+ x \\d+\", cell) != None: \n",
    "                self.ppw = cell\n",
    "        \n",
    "        '''\n",
    "        Python uses * for multiplication, not x, so we need to replace the x with\n",
    "        *. Then we evaluate the expression. Default is '2 x 2', so that would be\n",
    "        replaced with '2 * 2', which evaluates to 4.\n",
    "        '''\n",
    "        self.ppw = eval(self.ppw.replace(\"x\", \"*\"))\n",
    "        #self.ppw = points_per_well\n",
    "    \n",
    "    def create96Wellplate(self):\n",
    "        '''\n",
    "        Make all possible row/column com binations in a standard 96-well plate\n",
    "        '''\n",
    "        self.row_letters = list(self.plate_setup.index)\n",
    "        self.col_numbers = list(self.plate_setup.columns)\n",
    "        self.all_wells = set((row+col) for row in self.row_letters for col in self.col_numbers)\n",
    "    \n",
    "    def enumerateSamples(self):\n",
    "        '''\n",
    "        First create a list of all values in the plate_setup table. This will include all \n",
    "        replicates and any missing values.\n",
    "        '''\n",
    "        self.samples = [\n",
    "            self.plate_setup.iloc[row, col] \n",
    "            for row in range(8) \n",
    "            for col in range(12)\n",
    "        ]\n",
    "        \n",
    "        '''\n",
    "        Removing null values, ie empty wells\n",
    "        '''\n",
    "        self.samples = [sample for sample in self.samples if not pd.isnull(sample)]\n",
    "        \n",
    "        '''\n",
    "        Converting the list to a set will only return unique values, meaning that all\n",
    "        samples are in this object only once.\n",
    "        '''\n",
    "        self.samples = list(set(self.samples))\n",
    "    \n",
    "    def createReplicatesList(self):\n",
    "        def findReplicates(sample):\n",
    "            '''\n",
    "            Get bool dataframe with True at positions where the given value exists\n",
    "            '''\n",
    "            hits = self.plate_setup.isin([sample])\n",
    "\n",
    "            '''\n",
    "            Convert that result to column names\n",
    "            '''\n",
    "            hits_series = hits.any()\n",
    "            cols = list(hits_series[hits_series == True].index)\n",
    "\n",
    "            '''\n",
    "            Get row names \n",
    "            '''\n",
    "            rows = [list(hits[col][hits[col] == True].index) for col in cols]\n",
    "            rows = [j for i in rows for j in i] # needed to flatten a 2d list\n",
    "\n",
    "            '''\n",
    "            For a given sample, concatenate the row/col coordinate into a single list\n",
    "            '''\n",
    "            positions = [row+col for row,col in zip(*[rows,cols])]\n",
    "\n",
    "            return positions\n",
    "        \n",
    "        self.replicates = {\n",
    "            sample : findReplicates(sample) \n",
    "            for sample in self.samples\n",
    "        }\n",
    "        \n",
    "        self.cells = sum(list(self.replicates.values()), [])\n",
    "    \n",
    "    def setStartExcelCell(self):\n",
    "        '''\n",
    "        First, need to find the first cell in the excel spreadsheet that actually\n",
    "        could contain data. In the standard output of the tecan iControl software,\n",
    "        there are ~59 rows of metadata that need to be ignored.\n",
    "        '''\n",
    "        def findFirstDatatable():\n",
    "            self.found_first_datatable = False\n",
    "            for row in self.sheet.iter_rows():\n",
    "                for cell in row:\n",
    "                    if cell.value in self.all_wells:\n",
    "                        self.start_cell = cell.coordinate\n",
    "                        self.found_first_datatable = True\n",
    "                if self.found_first_datatable:\n",
    "                    break\n",
    "        \n",
    "        findFirstDatatable()\n",
    "        \n",
    "        def splitCellCoordinates():\n",
    "            '''\n",
    "            Excel labels columns as letters from A...Z and rows as numbers \n",
    "            (unfortunately, opposite from the 96-well plate labeling). We need to\n",
    "            split the start_cell coordinate (usually \"A60\") into two separate \n",
    "            lists. \n",
    "            '''\n",
    "            self.xl_col_letters = [char for char in self.start_cell if char.isalpha()]\n",
    "            self.xl_row_num = [char for char in self.start_cell if not char.isalpha()]\n",
    "\n",
    "            self.start_cell_split = [\n",
    "                ''.join(self.xl_col_letters), ''.join(self.xl_row_num)\n",
    "            ]\n",
    "        \n",
    "        splitCellCoordinates()\n",
    "    \n",
    "        self.start_row = int(self.start_cell_split[1])\n",
    "        '''\n",
    "        The end row is the end row for a particular well, ie the end row of that \n",
    "        data table. It should be equal exactly 4 + points_per_well away from the\n",
    "        start_row, where points_per_well is the number of measurements taken per \n",
    "        well. The +4 is for the temp, time, mean, and stdev rows\n",
    "        '''\n",
    "        self.end_row = self.start_row + 4 + self.ppw \n",
    "    \n",
    "    def getNumTimepoints(self):\n",
    "        '''\n",
    "        The start_row is where the first well was scanned, so it has the correct number\n",
    "        of columns based on the label and timepoints.\n",
    "        \n",
    "        This code iterates through all the cells in the start_row and checks if the cell\n",
    "        isn't empty before it adds it to the number of timepoints.\n",
    "        \n",
    "        Then it subtracts 1 for the data labels column to report the true number\n",
    "        of timepoints.\n",
    "        '''\n",
    "        self.num_timepoints = sum([\n",
    "            True if cell.value != None\n",
    "            else False\n",
    "            for cell in self.sheet[self.start_row]\n",
    "        ]) - 1\n",
    "    \n",
    "    def getAllDataTables(self):\n",
    "        def getWellTable(start_row, end_row):\n",
    "            '''\n",
    "            Get column names for each data table. This function will exit if the \n",
    "            well name is not in the list of well coordinates that contain samples.\n",
    "            '''\n",
    "            cols = [\n",
    "                cell.value \n",
    "                for row in self.sheet.iter_rows(min_row=start_row,max_row=start_row)\n",
    "                for cell in row\n",
    "            ]\n",
    "            \n",
    "            if cols[0] not in self.cells:\n",
    "                return None\n",
    "            else:\n",
    "                '''\n",
    "                Subset the cell values to only contain the data between the start_row and \n",
    "                end_row variables. This will only grab the data tables for each well.\n",
    "                '''\n",
    "                data = [self.data[row] for row in range(start_row,end_row)]\n",
    "\n",
    "                df = pd.DataFrame(data, columns=cols)\n",
    "\n",
    "                '''\n",
    "                Drop any columns containing NA values. This usually happens when you plan the\n",
    "                kinetic cycle to go for x amount of time, but stop it early.\n",
    "                '''\n",
    "                df.dropna(inplace=True, axis=1)\n",
    "                \n",
    "                '''\n",
    "                Set name to be the sample name.\n",
    "                '''\n",
    "                locator = [\n",
    "                    True if cols[0] in s\n",
    "                    else False\n",
    "                    for s in self.replicates.values()\n",
    "                ]\n",
    "                idx = locator.index(True)\n",
    "                df.name = list(self.replicates.keys())[idx]\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                The first column only has metadata, so set that to the dataframe index.\n",
    "                '''\n",
    "                df.set_index(cols[0], inplace=True)\n",
    "\n",
    "                time_min = [t/60 for t in df.iloc[0,:]]\n",
    "                time_hr = [round(t/3600, 3) for t in df.iloc[0,:]]\n",
    "\n",
    "                df.loc[\"Time [m]\"] = time_min\n",
    "                df.loc[\"Time [h]\"] = time_hr\n",
    "                df.sort_index(ascending = False, inplace=True)\n",
    "            \n",
    "            return df\n",
    "        '''\n",
    "        This will only return the data tables of wells with data. More specifically, it \n",
    "        will only return tables whose sample name is in the plate_setup file. This means \n",
    "        that you can have the code will ignore any blank cells, even if the plate reader \n",
    "        scanned those. Suppose that you had two separate experiments on the same plate. \n",
    "        You can keep the analysis separate by changing your plate_setup file. Or if\n",
    "        there are wells you just want to ignore, leave the plate_setup file blank there.\n",
    "        '''\n",
    "        self.all_datatables = []\n",
    "        for i in range(96):\n",
    "            self.all_datatables.append(getWellTable(self.start_row, self.end_row))\n",
    "            # 2 blank spaces in between data tables\n",
    "            self.start_row = self.end_row + 3\n",
    "            self.end_row = self.start_row + 4 + self.ppw\n",
    "        '''\n",
    "        Remove None values that are returned if the current data table is not in the replicates\n",
    "        list.\n",
    "        '''\n",
    "        self.all_datatables = [df for df in self.all_datatables if type(df) == pd.DataFrame]\n",
    "        \n",
    "        '''\n",
    "        Create time objects\n",
    "        '''\n",
    "        self.time_s = list(self.all_datatables[0].loc[\"Time [s]\"])\n",
    "        self.time_min = list(self.all_datatables[0].loc[\"Time [m]\"])\n",
    "        self.time_hr = list(self.all_datatables[0].loc[\"Time [h]\"])\n",
    "    \n",
    "    def concatAllReplicateTables(self):\n",
    "        '''\n",
    "        Nomenclature: \n",
    "            Groups = unique samples.\n",
    "            Samples = anything that data is being returned for, including replicates. Think\n",
    "            of it as sum(groups_i * replicates_i).\n",
    "            Replicate = samples for a given group.\n",
    "        '''\n",
    "        \n",
    "        def concatRepTable(group):\n",
    "            '''\n",
    "            Create a list of all data tables for all replicates of a given\n",
    "            sample group. Return a copy of that data table to modify them\n",
    "            independently of original data.\n",
    "            '''\n",
    "            reps = [\n",
    "                rep.copy()\n",
    "                for rep in self.all_datatables\n",
    "                if rep.name == group\n",
    "            ]\n",
    "\n",
    "            '''\n",
    "            Calculate the total number of observations for a given sample group\n",
    "            as the number of replicates multiplied by the number of measurements\n",
    "            take per well. This is used to rename the indices.\n",
    "            '''\n",
    "            n_obs = len(reps) * self.ppw\n",
    "\n",
    "            '''\n",
    "            All data tables currently have the first 6 columns with data that only\n",
    "            need to be present at the very top of the concatenated data table. \n",
    "            Drop those columns for all replicate data tables after the 1st one in \n",
    "            the list.\n",
    "            '''\n",
    "            for rep in reps[1:]:\n",
    "                rep.drop(rep.index[:6], inplace=True)\n",
    "\n",
    "            '''\n",
    "            Next, concat all the replicate data tables. Keep the 'StDev' and 'Mean'\n",
    "            rows for now. Although they are inaccurate, they are going to be updated\n",
    "            later.\n",
    "            '''\n",
    "            concatenated = pd.concat(reps)\n",
    "            idx = ['Time [s]', 'Time [m]', 'Time [h]', 'Temp. [°C]', 'StDev', 'Mean']\n",
    "            idx_arbitrary = [i for i in range(n_obs)]\n",
    "            idx.extend(idx_arbitrary)\n",
    "            concatenated.index = idx\n",
    "\n",
    "            '''\n",
    "            Finally, name each concatenated data frame with the sample group name.\n",
    "            '''\n",
    "\n",
    "            concatenated.name = group\n",
    "\n",
    "            return concatenated\n",
    "        \n",
    "        self.concatDataTables = [\n",
    "            concatRepTable(group)\n",
    "            for group in self.samples\n",
    "        ]\n",
    "    \n",
    "    def summarizeAllTimepoints(self):\n",
    "        def summarizeTimepoints(group):\n",
    "            '''\n",
    "            Grab a copy of concatentated data frame for the given group.\n",
    "            '''\n",
    "            concatenated = self.concatDataTables[self.samples.index(group)].copy()\n",
    "\n",
    "            '''\n",
    "            OD values start from the 7th column down. With this data-only data frame,\n",
    "            we can easily calculate the mean and standard deviation for each \n",
    "            timepoint, ie column.\n",
    "            '''\n",
    "            OD_only = concatenated.iloc[6:,:]\n",
    "            n_obs = len(OD_only)\n",
    "            avg_ODs = [round(col.mean(),4) for name,col in OD_only.items()]\n",
    "            sd_ODs = [round(col.std(),4) for name,col in OD_only.items()]\n",
    "\n",
    "            '''\n",
    "            Update mean and stdev values per timepoint to the concatenated dataframe.\n",
    "            '''\n",
    "            concatenated.loc[\"Mean\"] = avg_ODs\n",
    "            concatenated.loc[\"StDev\"] = sd_ODs\n",
    "\n",
    "            return concatenated\n",
    "        \n",
    "        for group in self.concatDataTables:\n",
    "            group = summarizeTimepoints(group.name)\n",
    "        \n",
    "        self.summary = self.concatDataTables # Easier naming convention, but points to same object\n",
    "        \n",
    "    def subtractBackgroundFromAll(self):\n",
    "        '''\n",
    "        Get average background OD for LB-only wells.\n",
    "        '''\n",
    "        self.background = self.summary[self.samples.index(\"Blank\")]\n",
    "        self.avg_background = list(self.background.loc[\"Mean\"])\n",
    "        def subtractBackground(group):\n",
    "            '''\n",
    "            Ignore subtracting background for the Blank data. Wouldn't hurt,\n",
    "            but it's not needed.\n",
    "            '''\n",
    "            if group == \"Blank\":\n",
    "                return\n",
    "\n",
    "            '''\n",
    "            This will subtract the mean background at each timepoint from \n",
    "            the mean OD for each timepoint.\n",
    "            '''\n",
    "            self.summary[self.samples.index(group)].loc[\"Mean\"] -= self.avg_background\n",
    "        \n",
    "        for group in self.summary:\n",
    "            subtractBackground(group.name)\n",
    "    \n",
    "    def formatFinalOutput(self, time_scale=\"hr\", graph_soft=\"R\"):\n",
    "        from math import sqrt\n",
    "        \n",
    "        '''\n",
    "        Keep track of times in different scales. Users may want the final\n",
    "        data in minutes as opposed to the default hours.\n",
    "        '''\n",
    "        self.times = {\n",
    "            \"sec\" : self.time_s,\n",
    "            \"min\" : self.time_min,\n",
    "            \"hr\" : self.time_hr\n",
    "        }\n",
    "        self.timelabels = {\n",
    "            \"sec\" : \"Time (s)\",\n",
    "            \"min\" : \"Time (min)\",\n",
    "            \"hr\" : \"Time (h)\"\n",
    "        }\n",
    "        \n",
    "        if time_scale not in self.times:\n",
    "            raise ValueError('''Invalid time_scale \\\"{}\\\" provided. \n",
    "            Valid time_scales: \\\"sec\\\" \\\"min\\\" \\\"hr\\\"'''.format(time_scale))\n",
    "        else:\n",
    "            self.time = self.times[time_scale]\n",
    "            self.timelabel = self.timelabels[time_scale]\n",
    "        \n",
    "        if graph_soft == \"R\":\n",
    "            '''\n",
    "            Keep track of final data format for saving.\n",
    "            '''\n",
    "            self.dataformat = \"_long_\"\n",
    "            \n",
    "            '''\n",
    "            Plotting in R works best with long data where each row is a single\n",
    "            observation. Here, each row will contain the time, mean \n",
    "            background-subtracted OD, the stdev of the ODs, the standard error,\n",
    "            and the group name. The standard error is calculated as the stdev\n",
    "            at a given timepoint, divided by the square root of the total\n",
    "            number of observations: \n",
    "            (number of replicates * number of measurements per well).\n",
    "            '''\n",
    "            self.n_realsamples = (len(self.samples) - 1) # subtract one for the Blank sample\n",
    "            self.long_timepoints = self.time * self.n_realsamples # repeat each timepoint for the total number of samples\n",
    "            \n",
    "            '''\n",
    "            Make a single long list of all mean ODs and stds, respectively.\n",
    "            '''\n",
    "            self.long_avg_ODs = [\n",
    "                mean_OD \n",
    "                for group in self.summary \n",
    "                for mean_OD in group.loc[\"Mean\"] \n",
    "                if group.name != \"Blank\"\n",
    "            ]\n",
    "            self.long_sd_ODs = [\n",
    "                sd \n",
    "                for group in self.summary \n",
    "                for sd in group.loc[\"StDev\"] \n",
    "                if group.name != \"Blank\"\n",
    "            ]\n",
    "            \n",
    "            '''\n",
    "            For all sample groups, calculate number of observations as \n",
    "            number of replicates * number of well measurements.\n",
    "            '''\n",
    "            self.long_nobs = [\n",
    "                len(repwells) * self.ppw\n",
    "                for group,repwells in self.replicates.items()\n",
    "                if group != \"Blank\"\n",
    "            ] * self.num_timepoints\n",
    "            \n",
    "            '''\n",
    "            Calculate standard error as standard deviation divided by\n",
    "            the square root of the number of observations.\n",
    "            '''\n",
    "            self.long_sem_ODs = [\n",
    "                round(sd / sqrt(n), 4)\n",
    "                for sd,n in zip(self.long_sd_ODs,self.long_nobs)\n",
    "            ]\n",
    "            \n",
    "            # Repeat group names for long data format\n",
    "            self.groups_long = [\n",
    "                [group.name] * len(self.time) # will repeat the group name. This notation only works with lists\n",
    "                for group in self.summary \n",
    "                if group.name != \"Blank\"\n",
    "            ]\n",
    "            self.groups_long = sum(self.groups_long, []) # flatten 2D list into a single list\n",
    "            \n",
    "            self.final = pd.DataFrame({\n",
    "                \"Time\" : self.long_timepoints,\n",
    "                \"Mean\" : self.long_avg_ODs,\n",
    "                \"StDev\" : self.long_sd_ODs,\n",
    "                \"SEM\" : self.long_sem_ODs,\n",
    "                \"Group\" : self.groups_long\n",
    "            })\n",
    "            self.final.name = \"long\"\n",
    "            return\n",
    "        elif graph_soft == \"excel\":\n",
    "            '''\n",
    "            Keep track of final data format for saving.\n",
    "            '''\n",
    "            self.dataformat = \"_wide_\"\n",
    "            \n",
    "            self.wide_avg_ODs = [\n",
    "                list(group.loc[\"Mean\"])\n",
    "                for group in self.summary\n",
    "                if group.name != \"Blank\"\n",
    "            ]\n",
    "            \n",
    "            self.wide_sd_ODs = [\n",
    "                list(group.loc[\"StDev\"])\n",
    "                for group in self.summary\n",
    "                if group.name != \"Blank\"\n",
    "            ]\n",
    "            \n",
    "            '''\n",
    "            Format number of observations appropriately\n",
    "            '''\n",
    "            self.wide_nobs = [\n",
    "                [len(repwells) * self.ppw] * self.num_timepoints\n",
    "                for group,repwells in myxl.replicates.items()\n",
    "                if group != \"Blank\"\n",
    "            ]\n",
    "            \n",
    "            self.wide_SEMs = [\n",
    "                [round(sd / sqrt(n), 4) for sd,n in zip(sd_list,group)]\n",
    "                for sd_list,group in zip(self.wide_sd_ODs,self.wide_nobs)\n",
    "            ]\n",
    "\n",
    "            self.wide_labels = [\n",
    "                [\"Mean\"] * len(self.wide_avg_ODs),\n",
    "                [\"StDev\"] * len(self.wide_sd_ODs),\n",
    "                [\"SEM\"] * len(self.wide_SEMs)\n",
    "            ]\n",
    "            \n",
    "            self.wide_labels = sum(self.wide_labels, []) # flattend\n",
    "\n",
    "            self.wide_group_names = [\n",
    "                group\n",
    "                for group in self.samples\n",
    "                if group != \"Blank\"\n",
    "            ] * 3 # repeat 3x for mean, stdev, sem\n",
    "\n",
    "            self.wide_time = self.time\n",
    "            # Need to add two extras for the Group and Type columns\n",
    "            self.wide_time = [\"All\", \"Time\"] + self.wide_time \n",
    "            \n",
    "            '''\n",
    "            First, construct the data frame with each row being the mean or\n",
    "            stdev of ODs for each group per timepoint. Then insert a \"Type\"\n",
    "            column to delineate between \"Mean\" and \"StDev\". Next, insert\n",
    "            a \"Group\" column to specify the sample group. Finally, append\n",
    "            the Time row to the beginning of the data frame.\n",
    "            '''\n",
    "            self.final = pd.DataFrame(sum([self.wide_avg_ODs,self.wide_sd_ODs,self.wide_SEMs],[]))\n",
    "            self.final.insert(0, value=self.wide_labels, column=\"Type\")\n",
    "            self.final.insert(1, value=self.wide_group_names, column=\"Group\")\n",
    "            self.tmpcols = [\"Group\",\"Type\"] + [i for i in range(self.num_timepoints)]\n",
    "            self.final = pd.DataFrame([self.wide_time], columns = self.tmpcols).append(self.final)\n",
    "            self.final.reset_index(drop=True, inplace=True)\n",
    "            del self.tmpcols\n",
    "            \n",
    "            self.final.name = \"wide\"\n",
    "            return\n",
    "        else: \n",
    "            raise ValueError(\"graph_soft: {} not known. Valid options: \\\"R\\\" or \\\"excel\\\"\".format(graph_soft))\n",
    "            \n",
    "    def graph(self, \n",
    "              figdim=(10,10), ftsize=20, \n",
    "              mksize=15, cpsize=5, lwd=3, mewd=2.5,\n",
    "              y_ax_label=\"OD600\",\n",
    "              graph_method=\"time series\",\n",
    "              save_name=\"\"\n",
    "             ):\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        import itertools\n",
    "        \n",
    "        if self.final.name == \"long\":\n",
    "            if graph_method == \"time series\":\n",
    "                '''\n",
    "                Create custom iterable of markers to cycle through. See examples here:\n",
    "                https://matplotlib.org/stable/api/markers_api.html\n",
    "                '''\n",
    "                my_markers = itertools.cycle((\"o\", \"s\", \"v\", \"p\", \"P\", \"X\", \"D\", \"h\", \"*\", \"^\", \"<\", \">\"))\n",
    "\n",
    "                '''\n",
    "                Next, I want to change the the linetypes to be different after the\n",
    "                markers beging to re-cycle from the beginning. Look at more line\n",
    "                types here: \n",
    "                https://matplotlib.org/3.0.3/gallery/lines_bars_and_markers/line_styles_reference.html\n",
    "                '''\n",
    "                solid_lines = [\"-\"] * 12\n",
    "                dashed_lines = [\"--\"] * 12\n",
    "                dotted_lines = [\":\"] * 12\n",
    "                my_linestyles = itertools.cycle(solid_lines + dashed_lines + dotted_lines)\n",
    "\n",
    "                fig = plt.figure(figsize=figdim) # dimensions of the figure w x h\n",
    "                fig.suptitle(self.file.split(\".\")[0][0:20], fontsize = ftsize, fontweight=\"bold\") # title\n",
    "\n",
    "\n",
    "                '''\n",
    "                Base matplotlib can only do plotting similar to base R. This plot is\n",
    "                only meant to be for quick reference. If you want a publication\n",
    "                quality plot, use ggplot in R or seaborn in python.\n",
    "                '''\n",
    "                groups = self.final.groupby(\"Group\")\n",
    "                for name,group in groups:\n",
    "                    plt.errorbar(x=group[\"Time\"], y=group[\"Mean\"], \n",
    "                                 yerr=group[\"SEM\"], \n",
    "                                 marker = next(my_markers),       # bulletpoint shapes\n",
    "                                 linestyle = next(my_linestyles),\n",
    "                                 mec = \"black\",                   # marker edge color\n",
    "                                 ms = mksize,                     # marker size\n",
    "                                 capsize = cpsize,                # size of horizontal edge on err bar\n",
    "                                 lw = lwd,                        # line width\n",
    "                                 mew = mewd,                      # marker edge width\n",
    "                                 label=name)                      # label for legend\n",
    "\n",
    "                plt.ylabel(y_ax_label, fontsize = ftsize, fontweight=\"bold\")\n",
    "                plt.xlabel(self.timelabel, fontsize = ftsize, fontweight=\"bold\")\n",
    "                plt.xticks(fontsize = ftsize * 0.75)\n",
    "                plt.yticks(fontsize = ftsize * 0.75)\n",
    "\n",
    "                # display legend - note that it's not ordered with the final OD\n",
    "                plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=(ftsize*0.75), edgecolor=\"black\")\n",
    "\n",
    "                '''\n",
    "                Adjust layout.\n",
    "                '''\n",
    "                plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "                \n",
    "                if save_name == \"\":\n",
    "                    self.save_plt_name = os.path.splitext(self.file)[0] + \"_PROCESSED.pdf\"\n",
    "                    self.save_plt_name = os.path.join(self.outdir,os.path.basename(self.save_plt_name))\n",
    "                else:\n",
    "                    self.save_plt_name = save_name\n",
    "                    \n",
    "                plt.savefig(self.save_plt_name)\n",
    "                print(\"Saved plot: {}\".format(self.save_plt_name))\n",
    "        \n",
    "        elif self.final.name == \"wide\":\n",
    "            print(\"No thanks. I hate wide data.\")\n",
    "            print(\"Just kidding, but if you want the plot, you need to set graphsoft=\\\"R\\\" for now.\")\n",
    "    \n",
    "    def saveFinalOutput(self, save_name=\"\"):\n",
    "        if save_name == \"\":\n",
    "            self.save_data_name = os.path.splitext(self.file)[0] + self.dataformat + \"PROCESSED.csv\"\n",
    "            self.save_data_name = os.path.join(self.outdir, os.path.basename(self.save_data_name))\n",
    "        else:\n",
    "            self.save_data_name = save_name\n",
    "\n",
    "        self.final.to_csv(self.save_data_name, index=None)\n",
    "        print(\"Saved file: {}\".format(self.save_data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/testdata1.xlsx\"\n",
    "plate = \"data/testdata1_key.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "myxl = WellPlate(data = file, setup = plate)\n",
    "myxl.create96Wellplate()\n",
    "myxl.enumerateSamples()\n",
    "myxl.createReplicatesList()\n",
    "#myxl.setActiveSheet() # no longer needed here\n",
    "myxl.setStartExcelCell()\n",
    "myxl.getNumTimepoints()\n",
    "myxl.getAllDataTables()\n",
    "myxl.concatAllReplicateTables()\n",
    "myxl.summarizeAllTimepoints()\n",
    "myxl.subtractBackgroundFromAll()\n",
    "myxl.formatFinalOutput()\n",
    "#myxl.saveFinalOutput()\n",
    "#myxl.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Mean</th>\n",
       "      <th>StDev</th>\n",
       "      <th>SEM</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.333</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1.667</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2.000</td>\n",
       "      <td>0.1006</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2.333</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2.667</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>3.000</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time    Mean   StDev     SEM Group\n",
       "0    0.000  0.0578  0.0642  0.0185    17\n",
       "1    0.333  0.0621  0.0659  0.0190    17\n",
       "2    0.667  0.0647  0.0657  0.0190    17\n",
       "3    1.000  0.0765  0.0649  0.0187    17\n",
       "4    1.333  0.0844  0.0638  0.0184    17\n",
       "..     ...     ...     ...     ...   ...\n",
       "205  1.667  0.1137  0.0669  0.0193     5\n",
       "206  2.000  0.1006  0.0679  0.0196     5\n",
       "207  2.333  0.0906  0.0692  0.0200     5\n",
       "208  2.667  0.0817  0.0687  0.0198     5\n",
       "209  3.000  0.0763  0.0701  0.0202     5\n",
       "\n",
       "[210 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myxl.final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "def main():\n",
    "    ###############\n",
    "    ## Arguments ##\n",
    "    ###############\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-i\", \"--input\", type=str, action=\"store\", help=\"Input file\", required=True)\n",
    "    parser.add_argument(\"-p\", \"--plate\", type=str, action=\"store\", help=\"Plate setup file\", required=True)\n",
    "    parser.add_argument(\"-a\", \"--active\", type=int, action=\"store\", help=\"Active data sheet\", default=0)\n",
    "    parser.add_argument(\"-gs\", \"--graphsoft\", type=str, action=\"store\", help=\"Set graphing program: R, excel\", default=\"R\")\n",
    "    parser.add_argument(\"-pp\", \"--produceplot\", action=\"store_false\", help=\"Autogenerate python plot: True/False\")\n",
    "    parser.add_argument(\"-y\", \"--yaxis\", type=str, action=\"store\", help=\"y-axis label on plot\", default=\"OD600\")\n",
    "    parser.add_argument(\"-gm\", \"--graphmeth\", type=str, action=\"store\", help=\"graphing method: time series, time diff\", default=\"time series\")\n",
    "    parser.add_argument(\"-pw\", \"--pointsperwell\", type=int, action=\"store\", help=\"readings per well\", default=4)\n",
    "    parser.add_argument(\"-ts\", \"--timescale\", type=str, action=\"store\", help=\"Time scale for data output and plotting\", default=\"hr\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    file = args.input\n",
    "    plate_setup_file = args.plate\n",
    "    active_sheet = args.active\n",
    "    graph_soft = args.graphsoft\n",
    "    produce_plot = args.produceplot\n",
    "    y_ax_label = args.yaxis\n",
    "    graph_method = args.graphmeth\n",
    "    points_per_well = args.pointsperwell\n",
    "    time_scale = args.timescale\n",
    "\n",
    "    print(\"\\ndata file:\", file)\n",
    "    print(\"plate setup:\", plate_setup_file)\n",
    "    print(\"active sheet:\", active_sheet + 1)\n",
    "    print(\"graphing software:\", graph_soft)\n",
    "    print(\"y axis label:\", y_ax_label)\n",
    "    print(\"graphing method:\", graph_method)\n",
    "    print(\"points per well:\", points_per_well)\n",
    "    print(\"producing python plot:\", produce_plot)\n",
    "    print(\"time scale:\", time_scale, \"\\n\")\n",
    "    \n",
    "    ##################\n",
    "    ## Process Data ##\n",
    "    ##################\n",
    "    data = WellPlate(data = file, setup = plate_setup_file, points_per_well=points_per_well)\n",
    "    data.create96Wellplate()\n",
    "    data.enumerateSamples()\n",
    "    data.createReplicatesList()\n",
    "    data.setActiveSheet(active_sheet)\n",
    "    data.setStartExcelCell()\n",
    "    data.getNumTimepoints()\n",
    "    data.getAllDataTables()\n",
    "    data.concatAllReplicateTables()\n",
    "    data.summarizeAllTimepoints()\n",
    "    data.subtractBackgroundFromAll()\n",
    "    \n",
    "    #################\n",
    "    ## Format Data ##\n",
    "    #################\n",
    "    data.formatFinalOutput(graph_soft=graph_soft, time_scale=time_scale)\n",
    "    data.saveFinalOutput()\n",
    "    if produce_plot:\n",
    "        data.graph(graph_method=graph_method)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
